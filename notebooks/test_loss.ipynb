{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%cd .."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/hien/Documents/models/reid/rep_reid\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Triplet Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hard Mining triplet loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO:"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weighted Regularization Triplet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "\n",
    "embedding_angles = [0, 20, 40, 60, 80]\n",
    "\n",
    "embeddings = torch.tensor(\n",
    "    [c_f.angle_to_coord(a) for a in embedding_angles],\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "labels = torch.LongTensor([0, 0, 1, 1, 2])\n",
    "embeddings, labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.0000],\n",
       "         [0.9397, 0.3420],\n",
       "         [0.7660, 0.6428],\n",
       "         [0.5000, 0.8660],\n",
       "         [0.1736, 0.9848]], requires_grad=True),\n",
       " tensor([0, 0, 1, 1, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from src.metrics import self_cosine_dist, self_euclidean_dist, self_cosine_similarity\n",
    "\n",
    "dist_mat = self_euclidean_dist(embeddings)\n",
    "dist_mat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1206, 0.4679, 1.0000, 1.6527],\n",
       "        [0.1206, 0.0000, 0.1206, 0.4679, 1.0000],\n",
       "        [0.4679, 0.1206, 0.0000, 0.1206, 0.4679],\n",
       "        [1.0000, 0.4679, 0.1206, 0.0000, 0.1206],\n",
       "        [1.6527, 1.0000, 0.4679, 0.1206, 0.0000]], grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "self_cosine_similarity(embeddings)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9397, 0.7660, 0.5000, 0.1736],\n",
       "        [0.9397, 1.0000, 0.9397, 0.7660, 0.5000],\n",
       "        [0.7660, 0.9397, 1.0000, 0.9397, 0.7660],\n",
       "        [0.5000, 0.7660, 0.9397, 1.0000, 0.9397],\n",
       "        [0.1736, 0.5000, 0.7660, 0.9397, 1.0000]], grad_fn=<MmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "self_cosine_dist(embeddings)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  6.0307e-02,  2.3396e-01,  5.0000e-01,  8.2635e-01],\n",
       "        [ 6.0307e-02,  0.0000e+00,  6.0307e-02,  2.3396e-01,  5.0000e-01],\n",
       "        [ 2.3396e-01,  6.0307e-02,  0.0000e+00,  6.0307e-02,  2.3396e-01],\n",
       "        [ 5.0000e-01,  2.3396e-01,  6.0307e-02,  0.0000e+00,  6.0307e-02],\n",
       "        [ 8.2635e-01,  5.0000e-01,  2.3396e-01,  6.0307e-02, -1.1921e-07]],\n",
       "       grad_fn=<RsubBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch.nn.functional as F\n",
    "embeddings2 = F.normalize(embeddings, p=2, dim=1)\n",
    "embeddings2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000],\n",
       "        [0.9397, 0.3420],\n",
       "        [0.7660, 0.6428],\n",
       "        [0.5000, 0.8660],\n",
       "        [0.1736, 0.9848]], grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "self_euclidean_dist(embeddings2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1206, 0.4679, 1.0000, 1.6527],\n",
       "        [0.1206, 0.0000, 0.1206, 0.4679, 1.0000],\n",
       "        [0.4679, 0.1206, 0.0000, 0.1206, 0.4679],\n",
       "        [1.0000, 0.4679, 0.1206, 0.0000, 0.1206],\n",
       "        [1.6527, 1.0000, 0.4679, 0.1206, 0.0000]], grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "self_cosine_similarity(embeddings2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9397, 0.7660, 0.5000, 0.1736],\n",
       "        [0.9397, 1.0000, 0.9397, 0.7660, 0.5000],\n",
       "        [0.7660, 0.9397, 1.0000, 0.9397, 0.7660],\n",
       "        [0.5000, 0.7660, 0.9397, 1.0000, 0.9397],\n",
       "        [0.1736, 0.5000, 0.7660, 0.9397, 1.0000]], grad_fn=<MmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "self_cosine_dist(embeddings2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  6.0307e-02,  2.3396e-01,  5.0000e-01,  8.2635e-01],\n",
       "        [ 6.0307e-02,  0.0000e+00,  6.0307e-02,  2.3396e-01,  5.0000e-01],\n",
       "        [ 2.3396e-01,  6.0307e-02,  0.0000e+00,  6.0307e-02,  2.3396e-01],\n",
       "        [ 5.0000e-01,  2.3396e-01,  6.0307e-02,  0.0000e+00,  6.0307e-02],\n",
       "        [ 8.2635e-01,  5.0000e-01,  2.3396e-01,  6.0307e-02, -1.1921e-07]],\n",
       "       grad_fn=<RsubBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 5\n",
    "targets = labels.view(batch_size, 1).expand(batch_size, batch_size)\n",
    "\n",
    "is_pos = targets.eq(targets.t()).float()\n",
    "is_neg = targets.ne(targets.t()).float()\n",
    "is_pos, is_neg"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0.],\n",
       "         [0., 0., 1., 1., 0.],\n",
       "         [0., 0., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 1.]]),\n",
       " tensor([[0., 0., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [1., 1., 0., 0., 1.],\n",
       "         [1., 1., 0., 0., 1.],\n",
       "         [1., 1., 1., 1., 0.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "dist_ap = dist_mat * is_pos\n",
    "dist_an = dist_mat * is_neg\n",
    "dist_ap, dist_an"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.1206, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1206, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.1206, 0.0000],\n",
       "         [0.0000, 0.0000, 0.1206, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<MulBackward0>),\n",
       " tensor([[0.0000, 0.0000, 0.4679, 1.0000, 1.6527],\n",
       "         [0.0000, 0.0000, 0.1206, 0.4679, 1.0000],\n",
       "         [0.4679, 0.1206, 0.0000, 0.0000, 0.4679],\n",
       "         [1.0000, 0.4679, 0.0000, 0.0000, 0.1206],\n",
       "         [1.6527, 1.0000, 0.4679, 0.1206, 0.0000]], grad_fn=<MulBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### softmax_weights"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "max_v = torch.max(dist_ap * is_pos, dim=1, keepdim=True)[0]\n",
    "max_v"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.1206],\n",
       "        [0.1206],\n",
       "        [0.1206],\n",
       "        [0.1206],\n",
       "        [0.0000]], grad_fn=<MaxBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "diff = dist_ap - max_v\n",
    "diff"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1206,  0.0000, -0.1206, -0.1206, -0.1206],\n",
       "        [ 0.0000, -0.1206, -0.1206, -0.1206, -0.1206],\n",
       "        [-0.1206, -0.1206, -0.1206,  0.0000, -0.1206],\n",
       "        [-0.1206, -0.1206,  0.0000, -0.1206, -0.1206],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "torch.sum(torch.exp(diff) * is_pos, dim=1, keepdim=True) + 1e-6\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.8864],\n",
       "        [1.8864],\n",
       "        [1.8864],\n",
       "        [1.8864],\n",
       "        [1.0000]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "torch.exp(diff) * is_pos / (\n",
    "    torch.sum(torch.exp(diff) * is_pos, dim=1, keepdim=True) + 1e-6\n",
    ")\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4699, 0.5301, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5301, 0.4699, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.4699, 0.5301, 0.0000],\n",
       "        [0.0000, 0.0000, 0.5301, 0.4699, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 1.0000]], grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def softmax_weights(dist, mask, eps=1e-6):\n",
    "    max_v = torch.max(dist * mask, dim=1, keepdim=True)[0]\n",
    "\n",
    "    diff = dist - max_v\n",
    "\n",
    "    Z = torch.sum(torch.exp(diff) * mask, dim=1, keepdim=True) + eps\n",
    "\n",
    "    W = torch.exp(diff) * mask / Z\n",
    "\n",
    "    return W\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight example mining"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "weights_ap = softmax_weights(dist_ap, is_pos)\n",
    "weights_an = softmax_weights(-dist_an, is_neg)\n",
    "weights_ap, weights_an"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.4699, 0.5301, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5301, 0.4699, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4699, 0.5301, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5301, 0.4699, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000]], grad_fn=<DivBackward0>),\n",
       " tensor([[0.0000, 0.0000, 0.5282, 0.3103, 0.1615],\n",
       "         [0.0000, 0.0000, 0.4713, 0.3330, 0.1956],\n",
       "         [0.2928, 0.4144, 0.0000, 0.0000, 0.2928],\n",
       "         [0.1956, 0.3330, 0.0000, 0.0000, 0.4713],\n",
       "         [0.0924, 0.1775, 0.3023, 0.4278, 0.0000]], grad_fn=<DivBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "dist_ap = torch.sum(dist_ap * weights_ap, dim=1)\n",
    "dist_an = torch.sum(dist_an * weights_an, dim=1)\n",
    "dist_ap, dist_an"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0.0639, 0.0639, 0.0639, 0.0639, 0.0000], grad_fn=<SumBackward1>),\n",
       " tensor([0.8244, 0.4083, 0.3240, 0.4083, 0.5233], grad_fn=<SumBackward1>))"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi similarity loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "\n",
    "embedding_angles = [0, 20, 40, 60, 80]\n",
    "\n",
    "embeddings = torch.tensor(\n",
    "    [c_f.angle_to_coord(a) for a in embedding_angles],\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "labels = torch.LongTensor([0, 0, 1, 1, 2])\n",
    "embeddings, labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.0000],\n",
       "         [0.9397, 0.3420],\n",
       "         [0.7660, 0.6428],\n",
       "         [0.5000, 0.8660],\n",
       "         [0.1736, 0.9848]], requires_grad=True),\n",
       " tensor([0, 0, 1, 1, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from pytorch_metric_learning.losses import MultiSimilarityLoss\n",
    "\n",
    "alpha, beta, base = 0.1, 10, 0.5\n",
    "\n",
    "loss_func = MultiSimilarityLoss(alpha=alpha, beta=beta, base=base)\n",
    "\n",
    "loss_func(embeddings, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(5.7961, grad_fn=<MeanBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from src.losses.multi_similarity_loss import MultiSimilarityLoss\n",
    "\n",
    "loss_func = MultiSimilarityLoss(alpha=alpha, beta=beta, gamma=base, eps=1e-12)\n",
    "\n",
    "loss_func(embeddings, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(5.7961, grad_fn=<MeanBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Circle loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "\n",
    "embedding_angles = [0, 20, 40, 60, 80]\n",
    "\n",
    "embeddings = torch.tensor(\n",
    "    [c_f.angle_to_coord(a) for a in embedding_angles],\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "labels = torch.LongTensor([0, 0, 1, 1, 2])\n",
    "embeddings, labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.0000],\n",
       "         [0.9397, 0.3420],\n",
       "         [0.7660, 0.6428],\n",
       "         [0.5000, 0.8660],\n",
       "         [0.1736, 0.9848]], requires_grad=True),\n",
       " tensor([0, 0, 1, 1, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from pytorch_metric_learning.losses import CircleLoss\n",
    "\n",
    "margin, gamma = 0.25, 256\n",
    "\n",
    "loss_func = CircleLoss(m=margin, gamma=gamma)\n",
    "\n",
    "loss_func(embeddings, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(176.0281, grad_fn=<MeanBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from src.losses.circle_loss import CircleLoss\n",
    "\n",
    "loss_func = CircleLoss(margin=margin, gamma=gamma)\n",
    "\n",
    "loss_func(embeddings, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(176.0281, grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cosface loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "\n",
    "embedding_angles = [0, 20, 40, 60, 80]\n",
    "\n",
    "embeddings = torch.tensor(\n",
    "    [c_f.angle_to_coord(a) for a in embedding_angles],\n",
    "    requires_grad=True,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "labels = torch.LongTensor([0, 0, 1, 1, 2])\n",
    "embeddings, labels\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.0000],\n",
       "         [0.9397, 0.3420],\n",
       "         [0.7660, 0.6428],\n",
       "         [0.5000, 0.8660],\n",
       "         [0.1736, 0.9848]], requires_grad=True),\n",
       " tensor([0, 0, 1, 1, 2]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from src.losses.cosface_loss import CosFace\n",
    "\n",
    "margin, gamma = 0.25, 256\n",
    "\n",
    "loss_func = CosFace(margin=margin, gamma=gamma)\n",
    "\n",
    "loss_func(embeddings, labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(52.8865, grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.9 64-bit ('rep_reid': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "interpreter": {
   "hash": "7c7a76c8265d47c17d5818f4f3eec0ba94be384b7470e37644b3c2ac337fea0b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}