{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0e43ebd82f4831ccc5d731d289760d07f38373204b3398fd7d3f971c463b78395",
   "display_name": "Python 3.9.2 64-bit ('yolov4': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from data.datasources import VOC2007\n",
    "from utils.image import visualize\n",
    "from data.transforms import Denormalize\n",
    "from data.datasets import ImageDataset_Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = VOC2007(\n",
    "    \"/home/hien/Documents/datasets\",\n",
    "    download=False,\n",
    "    extract=False,\n",
    "    use_tqdm=True,\n",
    "    bbox_type=\"albumentations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset_Yolo(\n",
    "    data=datasource.get_data(phase=\"train\"),\n",
    "    transform=A.Compose(\n",
    "        [\n",
    "            A.Resize(416, 416),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Rotate(limit=45, p=0.5),\n",
    "            A.PadIfNeeded(\n",
    "                min_height=416 + 10,\n",
    "                min_width=416 + 10,\n",
    "            ),\n",
    "            A.RandomCrop(416, 416),\n",
    "            A.RandomSizedCrop(\n",
    "                min_max_height=(\n",
    "                    int(416 * 2.0 / 3.0),\n",
    "                    416,\n",
    "                ),\n",
    "                height=416,\n",
    "                width=416,\n",
    "                p=1,\n",
    "            ),\n",
    "            A.Equalize(mode=\"cv\", p=0.8),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5\n",
    "            ),\n",
    "            A.ToGray(p=0.5),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(\n",
    "            format=\"albumentations\",\n",
    "            min_area=4500,\n",
    "            min_visibility=0.1,\n",
    "            label_fields=[\"category_ids\"],\n",
    "        ),\n",
    "    ),\n",
    "    bbox_type=\"albumentations\",\n",
    "    mosaic_prob=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(dataset)):\n",
    "    img, boxes, labels, difficulties = dataset.mosaic_test(i)\n",
    "\n",
    "    transformed_image = (\n",
    "        Denormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    visualize(\n",
    "        transformed_image,\n",
    "        boxes,\n",
    "        labels,\n",
    "        datasource.revert_label_map,\n",
    "        bbox_type=\"albumentations\",\n",
    "    )\n",
    "\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}