{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  8 14:39:06 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:37:00.0 Off |                    0 |\n",
      "| N/A   27C    P8     8W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   23C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.profiler\n",
    "import albumentations as A\n",
    "from multiprocessing import Manager\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from data.datasources import build_datasource\n",
    "from data.datasets.memory_dataset import DatasetCache\n",
    "from data.samplers import RandomIdentitySampler, RandomIdentitySampler\n",
    "from data.datasets.reid_dataset import ReidDataset\n",
    "from losses import build_losses\n",
    "from trainers.base import BaseTrainer\n",
    "from callbacks import Tqdm, FreezeLayers\n",
    "from models import build_model\n",
    "from optimizers import build_optimizers\n",
    "from schedulers import build_lr_scheduler\n",
    "from utils import MetricTracker\n",
    "from models.activations import get_activations\n",
    "from utils.ema import ModelEmaV2\n",
    "from metrics.accuracy import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_config(id, log_folder=\"saved/logs\", info_filename=\"info.log\"):\n",
    "    with open(os.path.join(log_folder, id, \"info.log\"), \"r\") as f:\n",
    "        line = f.readline()\n",
    "    return json.loads(\n",
    "        line[line.find(r\"\"\"{'timezone': \"\"\") : -1]\n",
    "        .replace(\"'\", '\"')\n",
    "        .replace(\"True\", \"true\")\n",
    "        .replace(\"False\", \"false\")\n",
    "        .replace(\"None\", \"null\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasource(config):\n",
    "    return build_datasource(\n",
    "        name=config[\"data\"][\"name\"],\n",
    "        root_dir=config[\"data\"][\"data_dir\"],\n",
    "        #     root_dir=\"/home/coder/project/datasets\",\n",
    "        download=False,\n",
    "        extract=False,\n",
    "        use_tqdm=config[\"data\"][\"use_tqdm\"],\n",
    "        relabel=config[\"data\"][\"relabel\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import remove_name_config\n",
    "\n",
    "\n",
    "def get_model(config, num_classes, id, model_name):\n",
    "    model = build_model(\n",
    "        name=config[\"model\"][\"name\"],\n",
    "        num_classes=num_classes,\n",
    "        backbone_name=config[\"model\"][\"backbone_name\"],\n",
    "        activation=get_activations(\n",
    "            config[\"model\"][\"activation\"][\"name\"],\n",
    "            **remove_name_config(config[\"model\"][\"activation\"]),\n",
    "        ),\n",
    "        pretrained=config[\"model\"][\"pretrained\"],\n",
    "        progress=config[\"model\"][\"progress\"],\n",
    "        pooling_name=config[\"model\"][\"pooling_name\"],\n",
    "        neck_feat=config[\"model\"][\"neck_feat\"],\n",
    "        head_name=config[\"model\"][\"head_name\"],\n",
    "        scale=config[\"model\"][\"scale\"],\n",
    "        margin=config[\"model\"][\"margin\"],\n",
    "        is_inference=True,\n",
    "    )\n",
    "\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(config[\"trainer\"][\"checkpoint_dir\"], id, model_name),\n",
    "        map_location=\"cpu\",\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transforms import build_transform\n",
    "\n",
    "\n",
    "def get_dataloader(config, datasource):\n",
    "    transform = build_transform(config[\"data\"][\"image_size\"], is_training=False)\n",
    "\n",
    "    dataset = dict()\n",
    "    dataset[\"query\"] = ReidDataset(\n",
    "        data=datasource.get_data(\"query\"),\n",
    "        transform=transform,\n",
    "        transform_lib=\"torchvision\",\n",
    "    )\n",
    "\n",
    "    dataset[\"gallery\"] = ReidDataset(\n",
    "        data=datasource.get_data(\"gallery\"),\n",
    "        transform=transform,\n",
    "        transform_lib=\"torchvision\",\n",
    "    )\n",
    "\n",
    "    dataloader = dict()\n",
    "\n",
    "    dataloader[\"query\"] = DataLoader(\n",
    "        dataset[\"query\"],\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    dataloader[\"gallery\"] = DataLoader(\n",
    "        dataset[\"gallery\"],\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def feature_extractor(model, data_loader, device):\n",
    "    r\"\"\"Extract feature from dataloader\n",
    "    Args:\n",
    "        model (models):\n",
    "        data_loader (Dataloader):\n",
    "        device (int): torch.device('cpu') if use_gpu == 0 else torch.device(n_gpu)\n",
    "    Return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    feature, label, camera = [], [], []\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        with tqdm(total=len(data_loader)) as pbar:\n",
    "            for i, batch in enumerate(data_loader):\n",
    "                x, y, cam_id = batch\n",
    "                x = x.to(device)\n",
    "                e = model(x)\n",
    "                feature.append(e.cpu())\n",
    "                label.extend(y)\n",
    "                camera.extend(cam_id)\n",
    "                pbar.update(1)\n",
    "    feature = torch.cat(feature, dim=0)\n",
    "    label = np.asarray(label)\n",
    "    camera = np.asarray(camera)\n",
    "    return feature, label, camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiennx/workspace/models/person_reid/rep_reid/metrics/mAP.py:19: UserWarning: Cython rank evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from metrics.distances import cosine_dist\n",
    "from metrics.mAP import evaluate_rank\n",
    "\n",
    "\n",
    "def get_mAP(config, id, model, dataloader, device):\n",
    "    query_feature, query_label, query_camera = feature_extractor(\n",
    "        model, dataloader[\"query\"], device\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.join(config[\"trainer\"][\"output_dir\"], id), exist_ok=True)\n",
    "\n",
    "    gallery_feature, gallery_label, gallery_camera = feature_extractor(\n",
    "        model, dataloader[\"gallery\"], device\n",
    "    )\n",
    "\n",
    "    if config[\"loss\"][\"triplet_distance_mode\"] == \"euclidean\":\n",
    "        distance = torch.cdist(query_feature, gallery_feature)\n",
    "    else:\n",
    "        distance = cosine_dist(query_feature, gallery_feature)\n",
    "\n",
    "    cmc, all_AP, all_INP = evaluate_rank(\n",
    "        distance, query_label, gallery_label, query_camera, gallery_camera\n",
    "    )\n",
    "\n",
    "    mAP = np.mean(all_AP)\n",
    "    mINP = np.mean(all_INP)\n",
    "\n",
    "    rank = dict()\n",
    "    for r in [1, 5, 10]:\n",
    "        rank[\"Rank-{}\".format(r)] = cmc[r - 1] * 100\n",
    "\n",
    "    return mAP, mINP, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from logger import setup_logging\n",
    "\n",
    "\n",
    "def main(id, device, model_name, before_285=False):\n",
    "    config = get_config(id)\n",
    "\n",
    "    os.makedirs(os.path.join(config[\"trainer\"][\"output_dir\"], id), exist_ok=True)\n",
    "\n",
    "    setup_logging(os.path.join(config[\"trainer\"][\"output_dir\"], id))\n",
    "\n",
    "    logger = logging.getLogger(\"test\")\n",
    "    logger.info(f\"ID: {id}\")\n",
    "    logger.info(f\"model_name: {model_name}\")\n",
    "\n",
    "    if before_285:\n",
    "        config[\"model\"][\"backbone_name\"] = \"resnet50\"\n",
    "\n",
    "    datasource = get_datasource(config)\n",
    "\n",
    "    model = get_model(config, len(datasource.get_classes()), id, model_name)\n",
    "\n",
    "    dataloader = get_dataloader(config, datasource)\n",
    "\n",
    "    mAP, mINP, rank = get_mAP(config, id, model, dataloader, device)\n",
    "\n",
    "    logger.info(f\"mAP: {mAP}\")\n",
    "    logger.info(f\"mINP: {mINP}\")\n",
    "    for key, value in rank.items():\n",
    "        logger.info(f\"{key}: {value}\")\n",
    "\n",
    "    logger.info(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0807_201910']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "list_id = [x for x in os.listdir(\"saved/logs\") if x.startswith(\"0807_201910\")]\n",
    "list_id.sort(reverse=True)\n",
    "\n",
    "list_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  8 14:39:46 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:37:00.0 Off |                    0 |\n",
      "| N/A   27C    P8     8W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   23C    P8     8W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model_name = [\n",
    "    \"model_best_triplet_loss.pth\",\n",
    "    \"model_last.pth\",\n",
    "    \"model_best_id_loss.pth\",\n",
    "    \"model_best_loss.pth\",\n",
    "    \"model_best_top1.pth\",\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 0807_201910\n",
      "model_name: model_best_triplet_loss.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27 [00:00<?, ?it/s]/opt/conda/envs/reid/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "100%|██████████| 125/125 [01:43<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.8690589616693651\n",
      "mINP: 0.6048882468719171\n",
      "Rank-1: 95.1603353023529\n",
      "Rank-5: 98.54512810707092\n",
      "Rank-10: 98.99049997329712\n",
      "\n",
      "ID: 0807_201910\n",
      "model_name: model_last.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "100%|██████████| 125/125 [01:43<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.8709392051214483\n",
      "mINP: 0.6079838044852977\n",
      "Rank-1: 95.33848166465759\n",
      "Rank-5: 98.57482314109802\n",
      "Rank-10: 99.02018904685974\n",
      "\n",
      "ID: 0807_201910\n",
      "model_name: model_best_id_loss.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:21<00:00,  1.26it/s]\n",
      "100%|██████████| 125/125 [01:43<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.8694681463529129\n",
      "mINP: 0.6089862068522865\n",
      "Rank-1: 94.98218297958374\n",
      "Rank-5: 98.45605492591858\n",
      "Rank-10: 98.87173175811768\n",
      "\n",
      "ID: 0807_201910\n",
      "model_name: model_best_loss.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:21<00:00,  1.23it/s]\n",
      "100%|██████████| 125/125 [01:44<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.8694681463529129\n",
      "mINP: 0.6089862068522865\n",
      "Rank-1: 94.98218297958374\n",
      "Rank-5: 98.45605492591858\n",
      "Rank-10: 98.87173175811768\n",
      "\n",
      "ID: 0807_201910\n",
      "model_name: model_best_top1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n",
      "100%|██████████| 125/125 [01:43<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP: 0.86893581391267\n",
      "mINP: 0.6038501630000047\n",
      "Rank-1: 95.21971344947815\n",
      "Rank-5: 98.48574995994568\n",
      "Rank-10: 98.84204268455505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name in list_model_name:\n",
    "    for id in list_id:\n",
    "        try:\n",
    "            main(id, device, model_name)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3**2086) % 440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reid",
   "language": "python",
   "name": "reid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
